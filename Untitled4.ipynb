{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classname=truck\n",
      "(4468, 32, 32, 3)\n",
      "(4468, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-4ea9172495af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimage_resized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;31m#return image_resized, one_hot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m \u001b[0mread_cifar10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-4ea9172495af>\u001b[0m in \u001b[0;36mread_cifar10\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mtraining_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0;31m#print(training_data[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mhstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions"
     ]
    }
   ],
   "source": [
    "# %load read_cifar10_direct\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "# %load read_cifar10_direct.py\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "# %load read_cifar10_direct.py\n",
    "\n",
    "\n",
    "# In[30]:\n",
    "\n",
    "\n",
    "from __future__ import print_function\n",
    "import traceback\n",
    "import sys\n",
    "import glob\n",
    "import os\n",
    "import tensorflow as tf\n",
    "#import matplotlib.image as mpimg # mpimg 用于读取图片\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "directory= '/home/dp/down/cifar10/cifar-10-unpack/classify' #目标文件夹\n",
    "classlist=list()\n",
    "\n",
    "def read_cifar10():\n",
    "         \n",
    "    images, labels = [], []\n",
    "    # 读取训练集\n",
    "    train_dir=os.path.join(directory,'train')\n",
    "    train_classlist=os.listdir(train_dir)\n",
    "\n",
    "    filenames=list()\n",
    "    labels=list()\n",
    "    for classes in train_classlist:\n",
    "        class_path=os.path.join(train_dir,classes)\n",
    "        filelist=os.listdir(class_path)\n",
    "        print('classname='+classes)\n",
    "        for file in filelist:\n",
    "            filefullName=os.path.join(class_path,file)\n",
    "            #image_string = tf.read_file(filefullName)\n",
    "            #image_decoded = tf.image.decode_png(image_string, channels=3)\n",
    "            #image_resized = tf.image.resize_images(image_decoded, [32, 32])\n",
    "            #image_decoded = mpimg.imread(filefullName) \n",
    "            image_decoded = Image.open(filefullName)\n",
    "            image_decoded = np.array(image_decoded, dtype=np.uint8)\n",
    "            \n",
    "            # 此时已经是一个 np.array 了，可以对它进行任意处理\n",
    "            image_decoded.reshape(32, 32, 3)\n",
    "            image_decoded = image_decoded.astype(float)\n",
    "            images.append(image_decoded)\n",
    "            labels_index=train_classlist.index(classes)\n",
    "            labels.append(labels_index)\n",
    "            \n",
    "            #print(image_decoded)\n",
    "        break   \n",
    "\n",
    "    #training_data = np.hstack(images, labels)\n",
    "    #np.random.shuffle(training_data)\n",
    "    #images = training_data[:, :-1]\n",
    "    #labels = training_data[:, -1]\n",
    "   \n",
    "    \n",
    "    images = np.array(images, dtype='float')\n",
    "    labels = np.array(labels, dtype='int')\n",
    "    labels=labels.reshape(4468,1)\n",
    "    print(images.shape)\n",
    "    print(labels.shape)\n",
    "    training_data = np.hstack((images, labels))\n",
    "    #print(training_data[0])\n",
    "    print(training_data[0])\n",
    "    #print(images,labels)\n",
    "    #self.train_images, self.train_labels = images, labels\n",
    "    \n",
    "# 函数的功能时将filename对应的图片文件读进来，并缩放到统一的大小\n",
    "def _parse_function(filename, label):\n",
    "    image_string = tf.read_file(filename)\n",
    "    image_decoded = tf.image.decode_png(image_string, channels=3)\n",
    "    image_resized = tf.image.resize_images(image_decoded, [28, 28])\n",
    "   \n",
    "    #one_hot = tf.one_hot(label, 10) #one_hot = tf.one_hot(label, NUM_CLASSES)\n",
    "    return image_resized, label\n",
    "    #return image_resized, one_hot\n",
    "read_cifar10()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
